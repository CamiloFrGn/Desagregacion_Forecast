{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c212a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script will be used to dissagregate the volume give either by our commercial intelligence or our own forecast model.\n",
    "There are 3 types of levels to this dissagregation. Abs_type = 1 which takes in the general volume of the month. Abs_type = 0\n",
    "gives us a dataframe from excel with the volume of each city. Abs_type = -1 gives us a dataframe from excel with \n",
    "the volume of each factory.\n",
    "\"\"\"\n",
    "#import libraries\n",
    "\n",
    "import pandas as pd # dataframe library\n",
    "import numpy as np #mathematical library\n",
    "import datetime #date library\n",
    "from dateutil.relativedelta import relativedelta #subtract periods to a date\n",
    "import sys #system exit\n",
    "import time\n",
    "\n",
    "#import our sql script to connecto to engine and return dataframe. In this case, \n",
    "#the %run is used to \"import\" our sql connection notebook\n",
    "\n",
    "%run ..\\sql\\connect_sql_server.ipynb\n",
    "#from ipynb.fs.full.connect_sql_server import querySQL --> this is another option to import another notebook when in the same folder\n",
    "\n",
    "#import warnings library to then avoid the warnings given by jupyter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c6f07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to send dataframe to excel\n",
    "def send_excel(df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general,country):\n",
    "    #get current datetime\n",
    "    now = pd.to_datetime(\"now\").strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    #create excel worksheet\n",
    "    create_excel = pd.ExcelWriter(\"../data/\"+country+\"/forecast_\" + now + \".xlsx\", engine='xlsxwriter') #create excel to save dataframe\n",
    "    df_stational_factor_hour.to_excel( create_excel, sheet_name=\"FE Hora Dia Planta\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    df_hour_general.to_excel( create_excel, sheet_name=\"FE Hora Dia\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    df_stational_factor_day.to_excel( create_excel, sheet_name=\"FE Dia Semana Planta\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    df_weekday_general.to_excel( create_excel, sheet_name=\"FE Dia Semana\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    create_excel.save() #save the workbook\n",
    "    \n",
    "#we need to create a dataframe to get the stational factors for each week, day of the week and factory\n",
    "def get_stational_factors(df_history,country,year_disaggregate,month_disaggregate,inactivate_temp,calendar_sql,volume,abs_type,active_factories):\n",
    "    \n",
    "    \n",
    "    #first organize the historic dataframe by date\n",
    "    #convert string date to datetime type\n",
    "    df_history['FechaEntrega'] = pd.to_datetime(df_history['FechaEntrega'])\n",
    "    df_history = df_history.sort_values(by=\"FechaEntrega\")\n",
    "    #filter out inactive factories\n",
    "    df_history = df_history[df_history.Planta.isin(active_factories.Centro)]\n",
    "    if len(inactivate_temp) > 0:\n",
    "            df_history = df_history[~df_history.Planta.isin(inactivate_temp)]\n",
    "    \n",
    "    df = df_history\n",
    "    \n",
    "    df_stational_factor_diasemana = df_history.groupby(['DiaSemana','Planta'])['totalEntregado'].sum()\n",
    "    \n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_diasemana = df_stational_factor_diasemana.reset_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-------------we will basically repeat the previous process but for stational HOUR factors-------------------\n",
    "    df_stational_factor_hour = df_history.groupby(['hora_entrega','Planta'])['totalEntregado'].sum()\n",
    "    \n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_hour = df_stational_factor_hour.reset_index()\n",
    "    \n",
    "    #convert columns to corresponding datatype for good measure.\n",
    "    df_stational_factor_hour['totalEntregado'] = df_stational_factor_hour['totalEntregado'].astype(float)\n",
    "    df_stational_factor_hour['hora_entrega'] = df_stational_factor_hour['hora_entrega'].astype(int)\n",
    "    #Replace nan values with 0\n",
    "    df_stational_factor_hour['totalEntregado'] = df_stational_factor_hour['totalEntregado'].fillna(0)\n",
    "    \n",
    "    #create dataframe to group volume totals by factory to then merge with the stational df\n",
    "    vol_por_planta_hour = df_stational_factor_hour.groupby('Planta')['totalEntregado'].sum()\n",
    "    #reset index to put factory as column\n",
    "    vol_por_planta_hour = pd.DataFrame(vol_por_planta_hour.reset_index())\n",
    "    #rename volumen column\n",
    "    vol_por_planta_hour.rename(columns = {'totalEntregado':'vol_total_planta'}, inplace = True)\n",
    "    \n",
    "    #left merge to get total of each factory in corresponding row\n",
    "    df_stational_factor_hour = pd.merge(df_stational_factor_hour, \n",
    "                      vol_por_planta_hour, \n",
    "                      on ='Planta', \n",
    "                      how ='left') \n",
    "    #create new column to get stational factor\n",
    "    df_stational_factor_hour['%FE_hour'] =  df_stational_factor_hour['totalEntregado']/df_stational_factor_hour['vol_total_planta']\n",
    "    df_stational_factor_hour = df_stational_factor_hour.sort_values([\"Planta\",\"hora_entrega\"])\n",
    "    \n",
    "    print(\"FACTORES ESTACIONALES HORA POR PLANTA\")\n",
    "    print(df_stational_factor_hour)\n",
    "    \n",
    "    #we will create an extra dataframe for factories that dont have stational factories\n",
    "    df_hour_general = df_stational_factor_hour.groupby('hora_entrega')['totalEntregado'].sum().reset_index()\n",
    "    df_hour_general['%FE_general'] = df_hour_general['totalEntregado']/df_hour_general['totalEntregado'].sum()\n",
    "\n",
    " \n",
    "    print(\"FACTORES ESTACIONALES HORA GENERAL\")\n",
    "    \n",
    "    print(df_hour_general)\n",
    "    #-------------we will basically repeat the previous process but for stational DAY factors-------------------\n",
    "    \n",
    "\n",
    "    df_stational_factor_day = df_history[df_history['DiaSemana'] != 1]\n",
    "    #groupby day and factory with the sum of total volume\n",
    "    df_stational_factor_day = df_stational_factor_day.groupby(['DiaSemana','Planta'])['totalEntregado'].sum()\n",
    "\n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_day = df_stational_factor_day.reset_index()\n",
    "    \n",
    "    #convert columns to corresponding datatype for good measure.\n",
    "    df_stational_factor_day['totalEntregado'] = df_stational_factor_day['totalEntregado'].astype(float)\n",
    "    df_stational_factor_day['DiaSemana'] = df_stational_factor_day['DiaSemana'].astype(int)\n",
    "    #Replace nan values with 0\n",
    "    df_stational_factor_day['totalEntregado'] = df_stational_factor_day['totalEntregado'].fillna(0)\n",
    "    \n",
    "    #create dataframe to group volume totals by factory to then merge with the stational df\n",
    "    vol_por_planta_day = df_stational_factor_day.groupby('Planta')['totalEntregado'].sum()\n",
    "    #reset index to put factory as column\n",
    "    vol_por_planta_day = pd.DataFrame(vol_por_planta_day.reset_index())\n",
    "    #rename volumen column\n",
    "    vol_por_planta_day.rename(columns = {'totalEntregado':'vol_total_planta'}, inplace = True)\n",
    "    \n",
    "    #left merge to get total of each factory in corresponding row\n",
    "    df_stational_factor_day = pd.merge(df_stational_factor_day, \n",
    "                      vol_por_planta_day, \n",
    "                      on ='Planta', \n",
    "                      how ='left')\n",
    "    \n",
    "    #add stational factor column\n",
    "    df_stational_factor_day['%FE_day'] =  df_stational_factor_day['totalEntregado']/df_stational_factor_day['vol_total_planta']\n",
    "    #sort the dataframe\n",
    "    df_stational_factor_day = df_stational_factor_day.sort_values([\"Planta\",\"DiaSemana\"])\n",
    "    \n",
    "    print(\"FACTORES ESTACIONALES DIA SEMANA POR PLANTA\")\n",
    "    \n",
    "    print(df_stational_factor_day)\n",
    "    \n",
    "    df_weekday_general = df_stational_factor_day.groupby('DiaSemana')['totalEntregado'].sum().reset_index()\n",
    "    df_weekday_general['%FE_general'] = df_weekday_general['totalEntregado']/df_weekday_general['totalEntregado'].sum()\n",
    "    \n",
    "    print(\"FACTORES ESTACIONALES DIA SEMANA EN GENERAL\")\n",
    "    \n",
    "    print(df_weekday_general)\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "        #-------------------we will get the stational factors by week and factory-------------------\n",
    "    \n",
    " \n",
    "    #groupby week and factory with the sum of total volume\n",
    "    df_stational_factor_week = df_history.groupby(['Semana_Relativa','Planta'])['totalEntregado'].sum()\n",
    "\n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_week = df_stational_factor_week.reset_index()\n",
    "\n",
    "    #filter weeks in history dataset\n",
    "    df_stational_factor_week = df_stational_factor_week[df_stational_factor_week.Semana_Relativa.isin(calendar_sql.Semanas_mes)]\n",
    "    \n",
    "    #find weeks that are not present in historic data but are in the month to dissaggregate\n",
    "    week_not_present = list(set(calendar_sql['Semanas_mes'].unique()).symmetric_difference(set(df_stational_factor_week['Semana_Relativa'].unique())))\n",
    "\n",
    "    \n",
    "    \n",
    "    #convert columns to corresponding datatype for good measure.\n",
    "    df_stational_factor_week['totalEntregado'] = df_stational_factor_week['totalEntregado'].astype(float)\n",
    "    df_stational_factor_week['Semana_Relativa'] = df_stational_factor_week['Semana_Relativa'].astype(int)\n",
    "    #Replace nan values with 0\n",
    "    df_stational_factor_week['totalEntregado'] = df_stational_factor_week['totalEntregado'].fillna(0)\n",
    "    \n",
    "    #create dataframe to group volume totals by factory to then merge with the stational df\n",
    "    vol_por_planta_week = df_stational_factor_week.groupby('Planta')['totalEntregado'].sum()\n",
    "    #reset index to put factory as column\n",
    "    vol_por_planta_week = pd.DataFrame(vol_por_planta_week.reset_index())\n",
    "    #rename volumen column\n",
    "    vol_por_planta_week.rename(columns = {'totalEntregado':'vol_total_planta'}, inplace = True)\n",
    "    \n",
    "    #left merge to get total of each factory in corresponding row\n",
    "    df_stational_factor_week = pd.merge(df_stational_factor_week, \n",
    "                      vol_por_planta_week, \n",
    "                      on ='Planta', \n",
    "                      how ='left') \n",
    "    #create new column to get stational factor\n",
    "    df_stational_factor_week['%FE_week'] =  df_stational_factor_week['totalEntregado']/df_stational_factor_week['vol_total_planta']\n",
    "    df_stational_factor_week = df_stational_factor_week.sort_values(by=\"Planta\") #sort our dataframe by factory\n",
    "    \n",
    "    #we will create an extra dataframe for factories that dont have stational factories\n",
    "    df_week_general = df_stational_factor_week.groupby('Semana_Relativa')['totalEntregado'].sum().reset_index()\n",
    "    df_week_general['%FE_general'] = df_week_general['totalEntregado']/df_week_general['totalEntregado'].sum()\n",
    "\n",
    "        \n",
    "    \"\"\" \n",
    "        \n",
    "    print(\"exitoso\")\n",
    "    return [df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51242d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Año Mes Planta TipoPlanta totalEntregado Semana_Relativa DiaSemana  \\\n",
      "0  2023   3   F006    Central           15.0               9         4   \n",
      "1  2023   3   F006    Central            8.0               9         4   \n",
      "2  2023   3   F006    Central          18.75               9         4   \n",
      "3  2023   3   F006    Central           5.25               9         4   \n",
      "4  2023   3   F006    Central          15.25               9         4   \n",
      "\n",
      "  FechaEntrega DiasOperativos  Ciudad hora_entrega  \n",
      "0   2023-03-01              2  Bogotá           12  \n",
      "1   2023-03-01              4  Bogotá           14  \n",
      "2   2023-03-01              6  Bogotá            8  \n",
      "3   2023-03-01              8  Bogotá           13  \n",
      "4   2023-03-01             10  Bogotá           16  \n"
     ]
    }
   ],
   "source": [
    "country = 'Colombia' #state the country\n",
    "cliente = '50117983'\n",
    "start_date_history = datetime.datetime(2023, 3, 1) #the start date for our model to analyze\n",
    "end_date_history = datetime.datetime(2023, 3 , 30) #the end date for our model to analyze\n",
    "df_history = querySQL(  \"{CALL SCAC_AP20_BaseDesagregacion_cliente_horas_V2 (?,?,?,?)}\", (country, cliente, start_date_history.strftime(\"%Y-%m-%d\"), end_date_history.strftime(\"%Y-%m-%d\") ) )\n",
    "print(df_history.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79441e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTORES ESTACIONALES HORA POR PLANTA\n",
      "     hora_entrega Planta  totalEntregado  vol_total_planta  %FE_hour\n",
      "0               7   F001           51.00            5485.5  0.009297\n",
      "9               8   F001          302.50            5485.5  0.055145\n",
      "21              9   F001          423.00            5485.5  0.077112\n",
      "33             10   F001          468.75            5485.5  0.085453\n",
      "45             11   F001          665.00            5485.5  0.121229\n",
      "..            ...    ...             ...               ...       ...\n",
      "80             13   FA04           38.00             442.5  0.085876\n",
      "92             14   FA04           10.50             442.5  0.023729\n",
      "104            15   FA04           46.50             442.5  0.105085\n",
      "116            16   FA04           31.50             442.5  0.071186\n",
      "128            17   FA04           23.75             442.5  0.053672\n",
      "\n",
      "[161 rows x 5 columns]\n",
      "FACTORES ESTACIONALES HORA GENERAL\n",
      "    hora_entrega  totalEntregado  %FE_general\n",
      "0              7          750.25     0.028013\n",
      "1              8         1650.25     0.061617\n",
      "2              9         1836.00     0.068553\n",
      "3             10         2070.75     0.077318\n",
      "4             11         2486.00     0.092823\n",
      "5             12         1997.50     0.074583\n",
      "6             13         3342.00     0.124784\n",
      "7             14         2794.25     0.104332\n",
      "8             15         3396.50     0.126819\n",
      "9             16         3263.75     0.121862\n",
      "10            17         1864.75     0.069626\n",
      "11            18          845.50     0.031569\n",
      "12            19          277.25     0.010352\n",
      "13            20          140.00     0.005227\n",
      "14            21           42.00     0.001568\n",
      "15            22           25.50     0.000952\n",
      "FACTORES ESTACIONALES DIA SEMANA POR PLANTA\n",
      "    DiaSemana Planta  totalEntregado  vol_total_planta   %FE_day\n",
      "0           2   F001          703.75            5485.5  0.128293\n",
      "12          3   F001         1172.75            5485.5  0.213791\n",
      "25          4   F001         1316.25            5485.5  0.239951\n",
      "37          5   F001          835.75            5485.5  0.152356\n",
      "49          6   F001         1008.50            5485.5  0.183848\n",
      "..        ...    ...             ...               ...       ...\n",
      "24          3   FA04           48.25             442.5  0.109040\n",
      "36          4   FA04          161.50             442.5  0.364972\n",
      "48          5   FA04           73.50             442.5  0.166102\n",
      "60          6   FA04           81.50             442.5  0.184181\n",
      "72          7   FA04           46.50             442.5  0.105085\n",
      "\n",
      "[73 rows x 5 columns]\n",
      "FACTORES ESTACIONALES DIA SEMANA EN GENERAL\n",
      "   DiaSemana  totalEntregado  %FE_general\n",
      "0          2         3289.00     0.123708\n",
      "1          3         4558.50     0.171458\n",
      "2          4         6163.00     0.231807\n",
      "3          5         4691.75     0.176469\n",
      "4          6         4361.50     0.164048\n",
      "5          7         3523.00     0.132510\n",
      "exitoso\n"
     ]
    }
   ],
   "source": [
    "year_disaggregate = 2023 # year to disaggregate \n",
    "month_disaggregate = 4\n",
    "volume = 134566 #only for abs_type = 1\n",
    "inactivate_temp = ['T001','T002','T003','T004','F014','F020','F031'] #place inactive factories if there are any\n",
    "abs_type = 1\n",
    "\"\"\"\n",
    "PARAMETROS:\n",
    "absorcionEstadistica = 1  -> get general volume\n",
    "absorcionEstadistica = 0  -> get volume by city\n",
    "absorcionEstadistica = -1 -> get volume by factory\n",
    "\n",
    "\"\"\"\n",
    "#get weeks corresponding to the desired month\n",
    "calendar_sql = querySQL( \"select * from SCAC_AT3_DiasHabilesFuente where pais = ? and año = ? and mes = ? order by [Fecha de entrega]\", (country,year_disaggregate,month_disaggregate) )\n",
    "#get active factories to filter out inactive\n",
    "active_factories = querySQL( \"select Centro, [Planta Unica] as Planta, [Desc Cluster] as Cluster, Ciudad_Cluster as Ciudad  from SCAC_AT1_NombreCluster where pais = ? and activo = 1 order by Centro\", (country) )\n",
    "#execute dissagregation\n",
    "df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general = get_stational_factors(df_history,country,year_disaggregate,month_disaggregate,inactivate_temp,calendar_sql,volume,abs_type,active_factories)\n",
    "send_excel(df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general,country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe8f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b489379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704407f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df7fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109877b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82391c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
