{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c212a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script will be used to dissagregate the volume give either by our commercial intelligence or our own forecast model.\n",
    "There are 3 types of levels to this dissagregation. Abs_type = 1 which takes in the general volume of the month. Abs_type = 0\n",
    "gives us a dataframe from excel with the volume of each city. Abs_type = -1 gives us a dataframe from excel with \n",
    "the volume of each factory.\n",
    "\"\"\"\n",
    "#import libraries\n",
    "\n",
    "import pandas as pd # dataframe library\n",
    "import numpy as np #mathematical library\n",
    "import datetime #date library\n",
    "from dateutil.relativedelta import relativedelta #subtract periods to a date\n",
    "import sys #system exit\n",
    "import time\n",
    "\n",
    "#import our sql script to connecto to engine and return dataframe. In this case, \n",
    "#the %run is used to \"import\" our sql connection notebook\n",
    "\n",
    "%run ..\\sql\\connect_sql_server.ipynb\n",
    "#from ipynb.fs.full.connect_sql_server import querySQL --> this is another option to import another notebook when in the same folder\n",
    "\n",
    "#import warnings library to then avoid the warnings given by jupyter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6f07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to send dataframe to excel\n",
    "def send_excel(df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general,country):\n",
    "    #get current datetime\n",
    "    now = pd.to_datetime(\"now\").strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    #create excel worksheet\n",
    "    create_excel = pd.ExcelWriter(\"../data/\"+country+\"/forecast_\" + now + \".xlsx\", engine='xlsxwriter') #create excel to save dataframe\n",
    "    df_stational_factor_hour.to_excel( create_excel, sheet_name=\"FE Hora Dia Planta\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    df_hour_general.to_excel( create_excel, sheet_name=\"FE Hora Dia\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    df_stational_factor_day.to_excel( create_excel, sheet_name=\"FE Dia Semana Planta\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    df_weekday_general.to_excel( create_excel, sheet_name=\"FE Dia Semana\", index=False ) #send dataframe day to excel sheet created previously\n",
    "    create_excel.save() #save the workbook\n",
    "    \n",
    "#we need to create a dataframe to get the stational factors for each week, day of the week and factory\n",
    "def get_stational_factors(df_history,country,year_disaggregate,month_disaggregate,inactivate_temp,calendar_sql,volume,abs_type,active_factories):\n",
    "    \n",
    "    \n",
    "    #first organize the historic dataframe by date\n",
    "    #convert string date to datetime type\n",
    "    df_history['FechaEntrega'] = pd.to_datetime(df_history['FechaEntrega'])\n",
    "    df_history = df_history.sort_values(by=\"FechaEntrega\")\n",
    "    #filter out inactive factories\n",
    "    df_history = df_history[df_history.Planta.isin(active_factories.Centro)]\n",
    "    if len(inactivate_temp) > 0:\n",
    "            df_history = df_history[~df_history.Planta.isin(inactivate_temp)]\n",
    "    \n",
    "    df = df_history\n",
    "    \n",
    "    df_stational_factor_diasemana = df_history.groupby(['DiaSemana','Planta'])['totalEntregado'].sum()\n",
    "    \n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_diasemana = df_stational_factor_diasemana.reset_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-------------we will basically repeat the previous process but for stational HOUR factors-------------------\n",
    "    df_stational_factor_hour = df_history.groupby(['hora_entrega','Planta'])['totalEntregado'].sum()\n",
    "    \n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_hour = df_stational_factor_hour.reset_index()\n",
    "    \n",
    "    #convert columns to corresponding datatype for good measure.\n",
    "    df_stational_factor_hour['totalEntregado'] = df_stational_factor_hour['totalEntregado'].astype(float)\n",
    "    df_stational_factor_hour['hora_entrega'] = df_stational_factor_hour['hora_entrega'].astype(int)\n",
    "    #Replace nan values with 0\n",
    "    df_stational_factor_hour['totalEntregado'] = df_stational_factor_hour['totalEntregado'].fillna(0)\n",
    "    \n",
    "    #create dataframe to group volume totals by factory to then merge with the stational df\n",
    "    vol_por_planta_hour = df_stational_factor_hour.groupby('Planta')['totalEntregado'].sum()\n",
    "    #reset index to put factory as column\n",
    "    vol_por_planta_hour = pd.DataFrame(vol_por_planta_hour.reset_index())\n",
    "    #rename volumen column\n",
    "    vol_por_planta_hour.rename(columns = {'totalEntregado':'vol_total_planta'}, inplace = True)\n",
    "    \n",
    "    #left merge to get total of each factory in corresponding row\n",
    "    df_stational_factor_hour = pd.merge(df_stational_factor_hour, \n",
    "                      vol_por_planta_hour, \n",
    "                      on ='Planta', \n",
    "                      how ='left') \n",
    "    #create new column to get stational factor\n",
    "    df_stational_factor_hour['%FE_hour'] =  df_stational_factor_hour['totalEntregado']/df_stational_factor_hour['vol_total_planta']\n",
    "    df_stational_factor_hour = df_stational_factor_hour.sort_values([\"Planta\",\"hora_entrega\"])\n",
    "    \n",
    "    print(\"FACTORES ESTACIONALES HORA POR PLANTA\")\n",
    "    print(df_stational_factor_hour)\n",
    "    \n",
    "    #we will create an extra dataframe for factories that dont have stational factories\n",
    "    df_hour_general = df_stational_factor_hour.groupby('hora_entrega')['totalEntregado'].sum().reset_index()\n",
    "    df_hour_general['%FE_general'] = df_hour_general['totalEntregado']/df_hour_general['totalEntregado'].sum()\n",
    "\n",
    " \n",
    "    print(\"FACTORES ESTACIONALES HORA GENERAL\")\n",
    "    \n",
    "    print(df_hour_general)\n",
    "    #-------------we will basically repeat the previous process but for stational DAY factors-------------------\n",
    "    \n",
    "\n",
    "    df_stational_factor_day = df_history[df_history['DiaSemana'] != 1]\n",
    "    #groupby day and factory with the sum of total volume\n",
    "    df_stational_factor_day = df_stational_factor_day.groupby(['DiaSemana','Planta'])['totalEntregado'].sum()\n",
    "\n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_day = df_stational_factor_day.reset_index()\n",
    "    \n",
    "    #convert columns to corresponding datatype for good measure.\n",
    "    df_stational_factor_day['totalEntregado'] = df_stational_factor_day['totalEntregado'].astype(float)\n",
    "    df_stational_factor_day['DiaSemana'] = df_stational_factor_day['DiaSemana'].astype(int)\n",
    "    #Replace nan values with 0\n",
    "    df_stational_factor_day['totalEntregado'] = df_stational_factor_day['totalEntregado'].fillna(0)\n",
    "    \n",
    "    #create dataframe to group volume totals by factory to then merge with the stational df\n",
    "    vol_por_planta_day = df_stational_factor_day.groupby('Planta')['totalEntregado'].sum()\n",
    "    #reset index to put factory as column\n",
    "    vol_por_planta_day = pd.DataFrame(vol_por_planta_day.reset_index())\n",
    "    #rename volumen column\n",
    "    vol_por_planta_day.rename(columns = {'totalEntregado':'vol_total_planta'}, inplace = True)\n",
    "    \n",
    "    #left merge to get total of each factory in corresponding row\n",
    "    df_stational_factor_day = pd.merge(df_stational_factor_day, \n",
    "                      vol_por_planta_day, \n",
    "                      on ='Planta', \n",
    "                      how ='left')\n",
    "    \n",
    "    #add stational factor column\n",
    "    df_stational_factor_day['%FE_day'] =  df_stational_factor_day['totalEntregado']/df_stational_factor_day['vol_total_planta']\n",
    "    #sort the dataframe\n",
    "    df_stational_factor_day = df_stational_factor_day.sort_values([\"Planta\",\"DiaSemana\"])\n",
    "    \n",
    "    print(\"FACTORES ESTACIONALES DIA SEMANA POR PLANTA\")\n",
    "    \n",
    "    print(df_stational_factor_day)\n",
    "    \n",
    "    df_weekday_general = df_stational_factor_day.groupby('DiaSemana')['totalEntregado'].sum().reset_index()\n",
    "    df_weekday_general['%FE_general'] = df_weekday_general['totalEntregado']/df_weekday_general['totalEntregado'].sum()\n",
    "    \n",
    "    print(\"FACTORES ESTACIONALES DIA SEMANA EN GENERAL\")\n",
    "    \n",
    "    print(df_weekday_general)\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "        #-------------------we will get the stational factors by week and factory-------------------\n",
    "    \n",
    " \n",
    "    #groupby week and factory with the sum of total volume\n",
    "    df_stational_factor_week = df_history.groupby(['Semana_Relativa','Planta'])['totalEntregado'].sum()\n",
    "\n",
    "    #reset index to get semana_relativa and planta as columns\n",
    "    df_stational_factor_week = df_stational_factor_week.reset_index()\n",
    "\n",
    "    #filter weeks in history dataset\n",
    "    df_stational_factor_week = df_stational_factor_week[df_stational_factor_week.Semana_Relativa.isin(calendar_sql.Semanas_mes)]\n",
    "    \n",
    "    #find weeks that are not present in historic data but are in the month to dissaggregate\n",
    "    week_not_present = list(set(calendar_sql['Semanas_mes'].unique()).symmetric_difference(set(df_stational_factor_week['Semana_Relativa'].unique())))\n",
    "\n",
    "    \n",
    "    \n",
    "    #convert columns to corresponding datatype for good measure.\n",
    "    df_stational_factor_week['totalEntregado'] = df_stational_factor_week['totalEntregado'].astype(float)\n",
    "    df_stational_factor_week['Semana_Relativa'] = df_stational_factor_week['Semana_Relativa'].astype(int)\n",
    "    #Replace nan values with 0\n",
    "    df_stational_factor_week['totalEntregado'] = df_stational_factor_week['totalEntregado'].fillna(0)\n",
    "    \n",
    "    #create dataframe to group volume totals by factory to then merge with the stational df\n",
    "    vol_por_planta_week = df_stational_factor_week.groupby('Planta')['totalEntregado'].sum()\n",
    "    #reset index to put factory as column\n",
    "    vol_por_planta_week = pd.DataFrame(vol_por_planta_week.reset_index())\n",
    "    #rename volumen column\n",
    "    vol_por_planta_week.rename(columns = {'totalEntregado':'vol_total_planta'}, inplace = True)\n",
    "    \n",
    "    #left merge to get total of each factory in corresponding row\n",
    "    df_stational_factor_week = pd.merge(df_stational_factor_week, \n",
    "                      vol_por_planta_week, \n",
    "                      on ='Planta', \n",
    "                      how ='left') \n",
    "    #create new column to get stational factor\n",
    "    df_stational_factor_week['%FE_week'] =  df_stational_factor_week['totalEntregado']/df_stational_factor_week['vol_total_planta']\n",
    "    df_stational_factor_week = df_stational_factor_week.sort_values(by=\"Planta\") #sort our dataframe by factory\n",
    "    \n",
    "    #we will create an extra dataframe for factories that dont have stational factories\n",
    "    df_week_general = df_stational_factor_week.groupby('Semana_Relativa')['totalEntregado'].sum().reset_index()\n",
    "    df_week_general['%FE_general'] = df_week_general['totalEntregado']/df_week_general['totalEntregado'].sum()\n",
    "\n",
    "        \n",
    "    \"\"\" \n",
    "        \n",
    "    print(\"exitoso\")\n",
    "    return [df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51242d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Año Mes Planta TipoPlanta totalEntregado Semana_Relativa DiaSemana  \\\n",
      "0  2023   1   F003    Central           17.0               1         4   \n",
      "1  2023   1   F003    Central          12.25               1         5   \n",
      "2  2023   1   F003    Central           6.25               1         5   \n",
      "3  2023   1   F003    Central            8.0               1         6   \n",
      "4  2023   1   F003    Central            3.0               1         6   \n",
      "\n",
      "  FechaEntrega DiasOperativos  Ciudad hora_entrega  \n",
      "0   2023-01-04              1  Bogotá           12  \n",
      "1   2023-01-05              6  Bogotá           16  \n",
      "2   2023-01-05              7  Bogotá            9  \n",
      "3   2023-01-06              9  Bogotá           12  \n",
      "4   2023-01-06             10  Bogotá           15  \n"
     ]
    }
   ],
   "source": [
    "country = 'Colombia' #state the country\n",
    "cliente = '50117983'\n",
    "start_date_history = datetime.datetime(2023, 1, 1) #the start date for our model to analyze\n",
    "end_date_history = datetime.datetime(2023, 4 , 3) #the end date for our model to analyze\n",
    "df_history = querySQL(  \"{CALL SCAC_AP20_BaseDesagregacion_cliente_horas_V2 (?,?,?,?)}\", (country, cliente, start_date_history.strftime(\"%Y-%m-%d\"), end_date_history.strftime(\"%Y-%m-%d\") ) )\n",
    "print(df_history.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79441e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTORES ESTACIONALES HORA POR PLANTA\n",
      "     hora_entrega Planta  totalEntregado  vol_total_planta  %FE_hour\n",
      "1               7   F001          189.50            6634.0  0.028565\n",
      "12              8   F001          934.50            6634.0  0.140865\n",
      "24              9   F001          785.50            6634.0  0.118405\n",
      "36             10   F001          764.50            6634.0  0.115240\n",
      "48             11   F001          745.25            6634.0  0.112338\n",
      "..            ...    ...             ...               ...       ...\n",
      "110            15   FA04           58.50             782.5  0.074760\n",
      "122            16   FA04           90.25             782.5  0.115335\n",
      "134            17   FA04           47.00             782.5  0.060064\n",
      "146            18   FA04           29.00             782.5  0.037061\n",
      "153            19   FA04            5.00             782.5  0.006390\n",
      "\n",
      "[167 rows x 5 columns]\n",
      "FACTORES ESTACIONALES HORA GENERAL\n",
      "    hora_entrega  totalEntregado  %FE_general\n",
      "0              6           16.00     0.000273\n",
      "1              7         2037.00     0.034714\n",
      "2              8         4412.00     0.075189\n",
      "3              9         4562.75     0.077758\n",
      "4             10         4649.50     0.079236\n",
      "5             11         4913.00     0.083727\n",
      "6             12         4945.00     0.084272\n",
      "7             13         6577.25     0.112089\n",
      "8             14         6885.50     0.117342\n",
      "9             15         7457.50     0.127090\n",
      "10            16         6662.75     0.113546\n",
      "11            17         3499.00     0.059630\n",
      "12            18         1460.75     0.024894\n",
      "13            19          410.50     0.006996\n",
      "14            20          143.50     0.002446\n",
      "15            21           29.00     0.000494\n",
      "16            22           18.00     0.000307\n",
      "FACTORES ESTACIONALES DIA SEMANA POR PLANTA\n",
      "    DiaSemana Planta  totalEntregado  vol_total_planta   %FE_day\n",
      "0           2   F001         1009.00            6634.0  0.152095\n",
      "13          3   F001         1319.25            6634.0  0.198862\n",
      "25          4   F001         1228.25            6634.0  0.185145\n",
      "37          5   F001         1112.00            6634.0  0.167621\n",
      "50          6   F001         1290.50            6634.0  0.194528\n",
      "..        ...    ...             ...               ...       ...\n",
      "24          3   FA04           86.00             782.5  0.109904\n",
      "36          4   FA04          201.00             782.5  0.256869\n",
      "49          5   FA04          154.75             782.5  0.197764\n",
      "62          6   FA04          172.50             782.5  0.220447\n",
      "75          7   FA04           74.00             782.5  0.094569\n",
      "\n",
      "[76 rows x 5 columns]\n",
      "FACTORES ESTACIONALES DIA SEMANA EN GENERAL\n",
      "   DiaSemana  totalEntregado  %FE_general\n",
      "0          2         8627.50     0.148070\n",
      "1          3         9771.75     0.167708\n",
      "2          4        10366.00     0.177907\n",
      "3          5        10558.25     0.181206\n",
      "4          6        10561.25     0.181258\n",
      "5          7         8381.75     0.143852\n",
      "exitoso\n"
     ]
    }
   ],
   "source": [
    "year_disaggregate = 2023 # year to disaggregate \n",
    "month_disaggregate = 4\n",
    "volume = 134566 #only for abs_type = 1\n",
    "inactivate_temp = ['T001','T002','T003','T004','F014','F020','F031'] #place inactive factories if there are any\n",
    "abs_type = 1\n",
    "\"\"\"\n",
    "PARAMETROS:\n",
    "absorcionEstadistica = 1  -> get general volume\n",
    "absorcionEstadistica = 0  -> get volume by city\n",
    "absorcionEstadistica = -1 -> get volume by factory\n",
    "\n",
    "\"\"\"\n",
    "#get weeks corresponding to the desired month\n",
    "calendar_sql = querySQL( \"select * from SCAC_AT3_DiasHabilesFuente where pais = ? and año = ? and mes = ? order by [Fecha de entrega]\", (country,year_disaggregate,month_disaggregate) )\n",
    "#get active factories to filter out inactive\n",
    "active_factories = querySQL( \"select Centro, [Planta Unica] as Planta, [Desc Cluster] as Cluster, Ciudad_Cluster as Ciudad  from SCAC_AT1_NombreCluster where pais = ? and activo = 1 order by Centro\", (country) )\n",
    "#execute dissagregation\n",
    "df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general = get_stational_factors(df_history,country,year_disaggregate,month_disaggregate,inactivate_temp,calendar_sql,volume,abs_type,active_factories)\n",
    "send_excel(df_stational_factor_hour,df_hour_general,df_stational_factor_day,df_weekday_general,country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe8f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b489379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704407f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df7fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109877b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82391c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
